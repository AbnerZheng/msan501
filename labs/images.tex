\chapter{Image Processing}

\setcounter{problem}{1}

\noindent The goal of this chapter is to exercise your understanding of all of the major components in Python: {\bf assignments, expressions, if and loop statements, functions, lists, and libraries}. To make things interesting, we will perform some cool image processing tasks: {\bf flipping horizontally, blurring, removing salt-and-pepper image noise, finding edges within images, and image sharpening}.  For example, \figref{sharpbonkers} demonstrates image sharpening.

\begin{marginfigure}
\begin{center}
\scalebox{.45}{\includegraphics{figures/bonkers-bw-zoom.png}}
\scalebox{.45}{\includegraphics{figures/bonkers-sharp-zoom.png}}
\end{center}
\caption{Bonkers the cat sharpened using {\tt sharpen.py}.}
\label{sharpbonkers}
\end{marginfigure}

\section{Installing PIL}

For image processing, we'll use PIL, so please follow the instructions carefully to install \href{http://pillow.readthedocs.org/en/latest/installation.html}{\textcolor{blue}{PIL, a fork of PILLOW}}.

\subsection{Install stuff on a mac}

First make sure {\tt brew} is installed; try this from Terminal app:

\begin{lstlisting}[style=BashInputStyle]
$ brew
\end{lstlisting}

\noindent If not there, go here: {\tt http://brew.sh} and it'll say to install do this:

\begin{lstlisting}[style=BashInputStyle]
$ ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
\end{lstlisting}

\noindent then

\begin{lstlisting}[style=BashInputStyle]
$ brew install python
\end{lstlisting}

\noindent That should give you pip as well.  Ignore warning about having 2 pythons installed.  Make sure python is using the brew version of python. All brew stuff is in {\tt /usr/local/Cellar/*} so you should see:

\begin{lstlisting}[style=BashInputStyle]
$ which python
/usr/local/bin/python
$ ls -l `which python`
lrwxr-xr-x  1 parrt  admin  33 Jul  5 12:19 /usr/local/bin/python@ -> ../Cellar/python/2.7.9/bin/python
\end{lstlisting}

\noindent Now, install all of the software you need before installing PIL:

\begin{lstlisting}[style=BashInputStyle]
$ brew install libtiff libjpeg webp little-cms2
\end{lstlisting}

\noindent then

\begin{lstlisting}[style=BashInputStyle]
$ pip install Pillow
\end{lstlisting}

\noindent If you get an error that ends with:

\begin{alltt}
    ...
    ImportError: cannot import name HTTPSHandler
\end{alltt}

\noindent then try reinstalling python:

\begin{lstlisting}[style=BashInputStyle]
$ brew reinstall python
\end{lstlisting}
\noindent Test it:

\begin{lstlisting}[style=BashInputStyle]
$ python
Python 2.7.9 (default, Jul  5 2015, 12:18:15) 
[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
>>> import PIL
>>>
\end{lstlisting}

\noindent there should be no error when you type {\tt import PIL}

\section{Getting started}

To get started, review how to access the \href{http://stackoverflow.com/questions/4117530/sys-argv1-meaning-in-script}{\textcolor{blue}{command-line arguments}} that every program running on a computer can accept. Here is a small program, {\tt view.py}, that accepts a filename as a command-line argument.

\begin{pyverbatim}
import sys
from PIL import Image
if len(sys.argv) != 2:
	print "$ python view.py imagefilename"
	sys.exit(1)
filename = sys.argv[1] # get the argument passed to us by operating system
img = Image.open(filename) # load file specified on the command line
img = img.convert("L") # grayscale
img.show()
\end{pyverbatim}

To run this program, launch a terminal on Mac or Linux. Then, move to the directory that contains {\tt view.py} that you saved/typed-in using terminal command {\tt cd} (change directory).  For example, if you are using directory {\tt msan501/images} under your home directory for this project, then type this for Mac:

\begin{lstlisting}[style=BashInputStyle]
cd /Users/YOURID/msan501/images
\end{lstlisting}

\noindent and this for Linux:

\begin{lstlisting}[style=BashInputStyle]
cd /home/YOURID/msan501/images
\end{lstlisting}

You can get a bunch of sample images that I use for these notes from github:

{\tt https://github.com/parrt/msan501/tree/master/labs/figures}

\noindent Now, we can execute our {\tt view.py} script and pass it an argument of {\tt obama.png}:

\begin{lstlisting}[style=BashInputStyle]
python view.py obama.png
\end{lstlisting}

For the remainder of this document, you'll see a \$ on the left of the command, indicating you should execute it from the command line:

\begin{lstlisting}[style=BashInputStyle]
$ python view.py obama.png
\end{lstlisting}

You can download all of the image files I use from canvas in the files area under {\tt projects/proj1}, but of course you can play around with whatever images you want.\sidenote{Remember, however, that all images used in this class and those stored on University equipment must be ``safe for work.'' Keep it G-rated please, with no offensive images popping up on your laptops or machines during lab etc.}

If you are using PyCharm, then you need to use the ``{\tt\small Edit configuration}'' dialog under the {\tt Run} menu.  All file names that we specify in the script parameters area, or from the command line, are relative to the {\em current working directory}. That is why we used {\tt cd} to change our working directory in the example above. For convenience, let's keep all of images and scripts in the same directory. For our purposes, let's assume that the directory is always {\tt\small /Users/YOURID/msan501/images} (Mac) or {\tt\small /home/YOURID/msan501/images} (Linux).

\scalebox{1}{\includegraphics{figures/edit-config.png}}

The ``Script parameters'' text field is where you provide the ``command-line arguments,'' despite the fact we are not actually using a command-line. That is why PyCharm calls it script parameters instead of command-line parameters.

\newpage\section{1. Flipping an image horizontally}

As a first task, you must create a script called {\tt flip.py} that shows the image provided as a program (command-line) argument in its original form and then flipped horizontally.  For example, \figref{flipped} shows the result of running script {\tt flip.py} on image {\tt eye.png}.

\begin{marginfigure}
\begin{center}
\scalebox{.49}{\includegraphics{figures/eye.png}} \scalebox{.49}{\includegraphics{figures/eye-flip.png}}
\end{center}
\caption{Flipping an image horizontally; the original is on the left.}
\label{flipped}
\end{marginfigure}

\subsection{Boilerplate code}

Here's the boilerplate or ``skeleton'' code (save as {\tt flip.py}) that we already know how to do but with a hole where you need to define a function called {\tt flip} and a hole where you need to call that function to perform the flipping:

\begin{pyverbatim}
import sys
from PIL import Image

# define your flip function here
...
if len(sys.argv)<=1:
	print "missing image filename"
	sys.exit(1)
filename = sys.argv[1]
img = Image.open(filename)
img = img.convert("L")
img.show()

# call your flip function here
...
img.show()
\end{pyverbatim}

If you are using PyCharm, your project file list area should look like the list in \figref{fliplist}. It assumes that you have downloaded two image files as well.

\begin{marginfigure}
\begin{center}
\scalebox{.8}{\includegraphics{figures/flip-proj-browser.png}}
\end{center}
\caption{Project file list after building the flip task}
\label{fliplist}
\end{marginfigure}

\subsection{Three new PIL pieces}

To write your {\tt flip} function, you will need {\bf three pieces we have not covered yet}. 

\begin{itemize}
\item {\tt img.size} returns a tuple containing the width and height of image {\tt img} so you can write code like this:
\begin{pyverbatim}
width, height = img.size
\end{pyverbatim}
You'll need the width and height to iterate over the pixels of the image.

\item {\tt img.copy()} duplicates image {\tt img}.  For our {\tt flip} function, it would be hard to modify the image in place because we would be overwriting pixels we would need to flip later. It's easier to create a copy of the image in flipped position. You can write code like this:\\
{\tt imgdup = img.copy()}

\item {\tt img.load()} is yet another weird name from PIL that actually returns an object that looks like a two-dimensional matrix. We have previously seen two-dimensional lists, which are really like lists of lists such as {\tt m = [[1,2], [3, 4]]} or reformatted to look like the matrix:
\begin{pyverbatim}
m = [[1, 2],
     [3, 4]]
\end{pyverbatim}
To get element {\tt 3}, we would use list index expression {\tt m[1][0]} because we want the list at index 1, {\tt m[1]}, and then element 0 within that list. The two-dimensional object returned by {\tt load()} uses similar notation. If we ask for the ``matrix'' with:
\begin{pyverbatim}
m = img.load()
\end{pyverbatim}
then we would use notation {\tt m[x,y]} to get the pixel at position ({\tt x}, {\tt y}).
\end{itemize}

You will use these functions for the remaining tasks so keep them in mind.

\subsection{Iterating over the image matrix}

{\bf Define function} {\tt flip} using the familiar syntax and have it take a parameter called {\tt img}, which will be the image we want to flip. The goal is to create a copy of this image, flip it, and return a copy so that we do not alter the incoming original image. To create {\tt flip}, write code that implements the following steps.

\begin{enumerate}
\item Use {\tt size} to define local variables {\tt width} and {\tt height}
\item Use {\tt copy()} to make a copy of the incoming image {\tt img} and save it in a local variable
\item Use {\tt load()} to get the two-dimensional pixel matrix out of the incoming image and the copy of the image. Store these results in two new local variables.
\item To walk over the two-dimensional image, we've learned we need every combination of {\tt x} and {\tt y}. That means we need a nested {\tt for} loop. Create a nested for loop that iterates over all {\tt x} and all {\tt y} values within the {\tt width} and {\tt height} of the image.
\item Within the inner loop, set pixels in the image copy to the appropriate pixel copied from the original image
\item At the end of the function, return the flipped image
\end{enumerate}

The only remaining issue is determining which pixel from the original image to copy into the ({\tt x}, {\tt y}) position in the image copy. The {\tt y} index will be the same since we are flipping horizontally. The {\tt x} index in the flipped image is index {\tt width-x-1} from the original image. Trying out a few sample indexes shows that this works well. For example, a flipped image with {\tt width=10} has its pixel at {\tt x=0} pulled from index {\tt x=10-0-1=9} in the original image. That's great, because it takes the image from all in the right in the original and copies it to the far left of the copy. Checking the opposite extreme, {\tt x=9} in the flipped image should be {\tt x=10-9-1=0} from the original image.

\subsection{Running your flip script}

{\bf To run the script from the command line}, make sure you are in the {\tt msan501/images} directory containing your scripts and images then do:

\begin{lstlisting}[style=BashInputStyle]
$ cd msan501/images
$ python flip.py eye.png
\end{lstlisting}

{\bf From PyCharm}, I right-click and then select ``Run.'' It will do nothing but print ``{\tt missing image filename}'' because we have not given it a parameter yet, but we need to do this so that PyCharm creates a run configuration. Now, use the edit configuration dialog to specify {\tt eye.png} as a parameter or any other image. ({\em Remember that the filename must refer to a file in the current working directory or must be fully qualified.}) Click ``Run'' now and it should bring out the two images.

\scalebox{.82}{\includegraphics{figures/flip-config.png}}

\subsection{What to do when the program doesn't work}

If you have problems, follow these steps:

\begin{enumerate}
\item Don't Panic! Relax and realize that you will solve this problem, even if it takes a little bit of messing around. Banging your head against the computer is part of your job. Remember that the computer is doing precisely what you tell it to do. There is no mystery.
\item  Determine precisely what is going on. Did you get an error message from Python?  Is it a syntax error? If so, review the syntax of all your statements and expressions. PyCharm is your friend here and should highlight erroneous things with a red squiggly underline. If you got an error message that has what we call a stack trace, a number of things could be wrong. For example, if I misspell {\tt show()} as {\tt shower()}, I get the following message:
\begin{alltt}\small
Traceback (most recent call last):
  File "/Users/parrt/msan501/images/flip.py", line 26, in <module>
    img.shower()
  File "/usr/local/lib/python2.7/site-packages/PIL/Image.py", line 605, in __getattr__
    raise AttributeError(name)
AttributeError: shower
\end{alltt}
In PyCharm, the ``{\tt /Users/parrt/msan501/images/flip.py}'' part of the trace will be a blue link that you can click on. It will take you to the exact location in your script where there is a problem. Look for anything that refers to that file.
\item If it does not look like it some simple misspelling, you might get lucky and find something in Google if you cut-and-paste that error message.
\item If your script shows the original image but not the flipped image, then you likely have a problem with your {\tt flip} function.
\item If your program is at least running and doing something, then insert print statements to figure out what the variables are and how far into the program you get before a craps out. That often tells you what the problem is.
\item Try using the debugger to step through your program in PyCharm. Set a breakpoint on for example the line {\tt filename = sys.argv[1]} by clicking in the gutter to the left of that line.  A red dot should appear, indicating there is a breakpoint there. Then click the little bug icon instead of the green triangle (which is run button). That will start execution and then stop at that line. You can look at all of the variables at that point. Then you can step forward line by line. Read how to use the debugger online.
\item  Definitely try to solve the problem yourself, but don't waste too much time. The TAs or I can typically help you out quickly so you can move forward.
\end{enumerate}

\section{2. Blurring}

In this task, we want to blur an image by removing detail as shown in \figref{blurred}. We will do this by creating a new image whose pixels are the average of the surrounding pixels for which we will use a 3x3 region as shown in \figref{region}. The pixel in the center of the region is the region to compute as we slide the region around an image. In other words, {\tt pixel[x,y]} is the sum of {\tt pixel[x,y]} and all surrounding pixels divided by 9, the total number of pixels.

\begin{marginfigure}
\begin{center}
\scalebox{.87}{\includegraphics{figures/pcb.png}}\\
\scalebox{.87}{\includegraphics{figures/pcb-blur.png}}
\caption{Blurring of a circuit board; the original is on top.}
%\vspace{1.5in}
\end{center}
\label{blurred}
\end{marginfigure}

To implement this, start with the boilerplate from the previous section, which you should put into script {\tt blur.py}. The only difference is that you must call soon-to-be-created function {\tt blur} not {\tt flip} as you had before. Now, let's start at the courses level of functionality and realize that we have to walk over every pixel in the image. (This is called {\em top-down design}.) 

\subsection{Blurring function}

{\bf Define function} {\tt blur} to take an {\tt img} parameter, just like the {\tt flip} function in the previous task.  In a manner very similar to {\tt flip}, write code in {\tt blur} to accomplish these steps:

\begin{enumerate}

\item Define local variables {\tt width} and {\tt height}.
\item Make a copy of the incoming image {\tt img} and save it in a local variable.
\item Get the two-dimensional pixel matrix out of the image copy. Store it in a new local variable called {\tt pixels}.
\item Create a nested for loop that iterates over all {\tt x} and all {\tt y} values within the {\tt width} and {\tt height} of the image.
\item Within the inner loop:
\begin{enumerate}
\item Call to-be-created function {\tt region3x3} with arguments {\tt img}, {\tt x}, and {\tt y} in store into local variable {\tt r}.
\item Set {\tt pixels[x,y]} in the image copy to the result of calling to-be-created function {\tt avg} with an argument of {\tt r}.
\end{enumerate}
\item At the end of the function, return the flipped image.
\end{enumerate} 

Following the top-down design strategy, let's {\bf define function} {\tt avg} since it's the easiest. Define {\tt avg} to take an argument called {\tt data} or another of your choice. This will be the list of 9 pixels returned by function {\tt region3x3}. The average of a set of numbers is their total divided by how many numbers there are. Python provides two useful functions here: {\tt sum(data)} and {\tt len(data)}.  (Naturally, {\tt sum} simply walks the list and accumulates values using a pattern we are familiar with.)

\subsection{Image regions}

\begin{marginfigure}
\begin{center}
\scalebox{.85}{\includegraphics{figures/region-edge.png}}
\end{center}
\captionof{figure}{Our 3x3 region has pixels outside of the image boundaries as we slide it around the image along the edges.}
\label{outofrange}
\end{marginfigure}

Now we need to {\bf define function} {\tt region3x3}.  Have it take three parameters as described above. This function creates and {\bf return a list of nine pixels}. The list includes the center pixel at {\tt x}, {\tt y} and the 8 adjacent pixels at N, S, E, W, ... as shown in \figref{region}. Create a series of assignments that look like this:



\begin{pyverbatim}
me = getpixel(img, x, y)
N = getpixel(img, x, y - 1)
...
\end{pyverbatim}

\noindent where function {\tt getpixel(img, x, y)} gets the pixel at {\tt x}, {\tt y} in image {\tt img}.  We can't use the more readable expression {\tt pixels[x,y]} in this case, as we'll see in a second. Collect all those pixel values into a list using {\tt [a,b,c,...]} list literal notation and return it. Make sure that this list is a list of integers and exactly 9 elements long and that you keep in mind the order in which you add these pixels to the list. Any function that we create to operate on a region naturally needs to know the order so we can properly extract pixels from the list. For example, my implementation always puts the pixel at {\tt x} and {\tt y} first, then North, etc...

~\\
\begin{minipage}{0.8 \linewidth}
\makebox[\linewidth]{%
\scalebox{.8}{\includegraphics{figures/region.png}}
}
\captionof{figure}{Hyper-zoom of Obama's forehead showing 3x3 region.}
\label{region}
\end{minipage}

\subsection{Safely examining region pixels}

We need to {\tt define a function} {\tt getpixel} instead of directly accessing pixels because some of the pixels in our 3x3 region will be outside of the image as we shift the region around. For example, when we start out at {\tt x=0}, {\tt y=0}, 5 of the pixels will be out of range, as shown in \figref{outofrange}.  Accessing {\tt pixels[-1,-1]} will trigger:

{\tt IndexError: image index out of range}

\noindent and stop the program. To avoid this error and provide a suitable definition for the ill-defined pixels on the edges, we will use a function that ensures all indices are within range.

{\bf Define function} {\tt getpixel} with the appropriate parameters. Its functionality is as follows:
\begin{enumerate}
\item Get the width and height into local variables.
\item If the {\tt x} value is less than 0, set it to 0.
\item If the {\tt x} value is greater than or equal to the width, set it to the width minus 1 (the last  valid pixel on the far right).
\item If the {\tt y} value is less than 0, set it to 0.
\item If the {\tt y} value is greater than or equal to the height, set it to the  height minus 1 (the last felt pixel on the bottom).
\item Return the pixel at {\tt x}, {\tt y}. You will need to use the {\tt img.load()} function again to get the 2D {\tt pixels} matrix as you did in function {\tt blur}. Make sure you returning pixel and not the coordinates of the pixel from {\tt getpixel}.
\end{enumerate}

\subsection{Testing your blur code}

That is a lot of code to enter and so more than likely it won't work the first time.\sidenote{It never does, dang it!} That means we should test the pieces. It's generally a good idea to do top-down design but {\em bottom-up testing}. In other words, let's test the simple low-level functions first and make sure that works before testing the functions that call those functions and so on until we reach the outermost script. 

With that in mind, lets {\bf test} {\tt avg} by passing it a fixed list of numbers to see if we get the right number. Add this to your script before it does any of the file loading stuff:

\begin{pyverbatim}
print avg([1,2,3,4,5])
\end{pyverbatim}

\noindent Then run {\tt blur.py} with any old image; the {\tt apple.png} file is a good one because it's small:

\begin{lstlisting}[style=BashInputStyle]
$ python blur.py apple.png
3
$ 
\end{lstlisting}

\noindent If it does not print $(1+2+3+4+5)/5 = 3$, then you know you have a problem in {\tt avg}.

Now {\bf test} {\tt getpixel}. You will have to insert some code after loading and converting the image to grayscale because {\tt getpixel} takes an image parameter:

\begin{pyverbatim}
img = Image.open(filename)
img = img.convert("L")
print getpixel(img, 0, 0)
print getpixel(img, 0, 1)
print getpixel(img, 10, 20)
\end{pyverbatim}

\noindent  That should print: 96, 96, and 255. The upper left corner is gray and pixel 10, 20 is somewhere in the middle of the white Apple logo. If you don't get those numbers, then you have a problem with {\tt getpixel}. Worse, if you don't get simple numbers, then you really have a problem with {\tt getpixel}.

Before getting to {\tt blur}, we should also {\bf test} {\tt region3x3} to ensure it gets the proper region surrounding a pixel. Replace those {\tt getpixel} calls in the {\tt print} {\tt getpixel} statements with calls to {\tt region3x3}. Use the {\tt x}, {\tt y} of the upper left-hand corner and somewhere near the upper left of the white section of the logo such as:

\begin{pyverbatim}
print region3x3(img, 0, 0)
print region3x3(img, 7, 12)
\end{pyverbatim}

\noindent That checks whether we get an out of range error at the margins and that we get the correct region from somewhere in the middle. Running the script should give you the following numbers:

\begin{lstlisting}[style=BashInputStyle]
$ python blur.py apple.png
[96, 96, 96, 96, 96, 96, 96, 96, 96]
[255, 176, 255, 255, 215, 96, 245, 255, 255]
$ 
\end{lstlisting}

\noindent That assumes order: current pixel, N, S, E, W, NW, NE, SE, SW.

When you have verified that all of these functions work, it's time to check function {\tt blur} itself. Try the printed circuit board image:

\begin{lstlisting}[style=BashInputStyle]
$ python blur.py pcb.png 
\end{lstlisting}

\noindent That should pop up the original circuit board and the blurred version. It might take 10 seconds or more to compute and display the blurred image, depending on how fast your computer is.

\begin{callout}{\bctakecare}
Make sure to remove all of your debugging code before submitting your scripts. Submitting a project with a bunch of random debugging output is considered sloppy, like submitting an English paper with a bunch of handwritten edits.
\end{callout}

\section{3. Removing noise}

For our next task, we are going to de-noise (remove noise) from an image as shown in \figref{obama}. It does a shockingly good job considering the simplicity of our approach. To blur, we used the average of all pixels in the region. To denoise, we will use the \href{http://en.wikipedia.org/wiki/Median}{\textcolor{blue}{median}}, which is just the middle value in a list of ordered numbers.

\begin{marginfigure}
\begin{center}
(a) \scalebox{.5}{\includegraphics{figures/guesswho.png}}\\
(b) \scalebox{.5}{\includegraphics{figures/guesswho-denoise.png}}\\
(c) \scalebox{.5}{\includegraphics{figures/guesswho-denoise-denoise.png}}\\
(d) \scalebox{.5}{\includegraphics{figures/obama.png}}
\end{center}
\captionof{figure}{Denoising an image of President Obama with lots of salt-and-pepper noise. (a) the noisy image, (b) denoised as computed by {\tt denoise.py}, (c) denoised 2x, (d) original.}
\label{obama}
\end{marginfigure}

Believe it or not, we can implement the noise by copying {\tt blur.py} into a new script called {\tt denoise.py} and then changing a few lines.  We also have to remove the  no-longer-used {\tt avg} function and replace it with a {\tt denoise} function.  Of course, instead of calling {\tt blur}, we'll call function {\tt denoise} with the usual {\tt img} argument. The only difference between {\tt denoise} and {\tt blur} is that you will set the pixel to the {\tt median} not {\tt avg}.  Hint: you need to tweak one statement in the inner loop that moves over all pixel values.

{\bf Now define function} {\tt median} that, like {\tt avg}, takes a list of 9 numbers called {\tt data}. Sort the list using Python's {\tt sorted} function that takes a list and returns a sorted version of that list. Then compute the index of the middle list element, which is just the length of the list divided by two. If the length is even, dividing by 2 (not 2.0) will round it down to the nearest index. Once you have this index, return the element at that index.

Let's give it a test:

\begin{lstlisting}[style=BashInputStyle]
$ python denoise.png guesswho.png
\end{lstlisting}

\noindent That should pop up the noisy Obama and the cleaned up version. You can save the cleaned up version and run {\tt denoise.py} on that one to really improve it.\sidenote[][.5in]{Hint: {\bf To save an image with PIL}, use {\tt img.save("filename.png")}.} Running {\tt denoise.py} twice, gives the cleaned up image (c) from \figref{obama}.  

\vspace{10mm}
\newpage\section{4. Re-factoring to improve code quality}

As I mentioned in the last task, {\tt blur.py} and {\tt denoise.py} are virtually identical, meaning that we have a lot of code in common. \figref{vizdiff} demonstrates this visually. One of the most important principles of computer science is to reduce code duplication. We always want exactly one place to change a particular bit of functionality.   In this case, we have the following common code:

\begin{marginfigure}
\begin{center}
\scalebox{.95}{\includegraphics{figures/blur-denoise-diff.png}}
\end{center}
\caption{Visual difference between scripts {\tt blur.py} and {\tt denoise.py}. The files are identical except for orange marks.}
\label{vizdiff}
\end{marginfigure}

\begin{enumerate}
\item Functions {\tt getpixel} and {\tt region3x3}.
\item The ``main'' part of the script that loads the original image.
\item Functions {\tt blur} and {\tt denoise} are identical except for the function called to compute a new pixel in the image copy from a 3x3 region in the original ({\tt avg} or {\tt median}).
\end{enumerate}

The goal of this task is to make new versions, {\tt blur2.py} and {\tt denoise2.py}, that share as much code as possible.  The functionality will be the same, but they will be much smaller and we will get warm feeling that our code is well structured. To share code, we need to (a) put all common code in a file that these new scripts can import and (b) create a generic function called {\tt filter} that will work for both blurring and de-noising in an image. Once we get the common code into a single file, which we will call {\tt filter.py}, we can import it into {\tt blur2.py} and {\tt denoise2.py} like this:\sidenote{Do not confuse script names with function names; {\tt filter.py} can contain anything we want and it so happens that we will also put a function in there with the same name, {\tt filter}.}
 
\begin{pyverbatim}
from filter import *
\end{pyverbatim}

\noindent That statement asks Python to look in the current directory (among other places we don't care about for now) for file called {\tt filter.py} and import all of the functions. You can think of it as a formalized cut-and-paste.

Let's start by creating new ``library'' file {\tt filter.py} and placing our usual imports at the top:

\begin{pyverbatim}
import sys
from PIL import Image
\end{pyverbatim}

\noindent Now, copy functions {\tt getpixel} and {\tt region3x3} into it.

We can also create a function called {\tt open} to hide all of the messiness that checks for command-line arguments and opens the indicated image:

\begin{pyverbatim}
def open(argv):
	if len(argv)<=1:
		print "missing image filename"
		sys.exit(1)
	img = Image.open(argv[1])
	img = img.convert("L")  # make greyscale if not already (luminance)
	return img
\end{pyverbatim}

The only tricky bit\sidenote{Pun intended} is to create a single generic {\tt filter} function that can reproduce the functionality we have in functions {\tt blur} and {\tt denoise}.

\begin{enumerate}
\item Define function {\tt filter} to take {\tt img} and {\tt f} parameters.
\item Copy the body of function {\tt blur} into your new {\tt filter} function.
\item Replace the call to {\tt avg(r)} with {\tt f(r)}.
\end{enumerate}

As we discussed in class, functions are objects in Python just like any strings, lists, and so on. That means we can pass them around as function arguments.\sidenote{Don't confuse the name of a function with an expression that calls it.  Assignment {\tt f = avg} makes variable {\tt f} refer to function {\tt avg}. {\tt f = avg()} {\bf calls} function {\tt avg} and stores the return value in variable {\tt f}. Using {\tt f = avg}, we can call {\tt avg} with expression {\tt f()}. You can think of {\tt f} as an alias for {\tt avg}.} To use our new generic {\tt filter} function, we pass it an image as usual but also the name of a function:

\begin{pyverbatim}
blurred  = filter(img, avg)
denoised = filter(img, median)
\end{pyverbatim}

In the end, your {\tt filter.py} script file should have 4 functions: {\tt getpixel}, {\tt region3x3}, {\tt filter}, and {open}.

Armed with this awesome new common file, our entire {\tt blur2.py} file shrinks to a tiny script:\sidenote{You might be wondering why we don't have to include the usual {\tt sys} and {\tt PIL} imports at the start of our new files. That is because we import our {\tt filter.py} file, which in turn imports those files.}

\begin{pyverbatim}
from filter import *
# Your avg function goes here (copy from blur.py)
...
img = open(sys.argv)
img.show()
img = filter(img, avg)		# blur me please
img.show()
\end{pyverbatim}

\noindent The {\tt denoise2.py} script is also tiny:\sidenote{Yep, these files are identical except for the fact that we call {\tt filter} with different function names. If you wanted to get really fancy, you could replace both of these scripts with a single script that took a function name as a second argument (after the image filename).  With some magic incantations, you'd then ask Python to lookup the function with the indicated name and pass it to function {\tt filter} instead of hard coding.}

\begin{pyverbatim}
from filter import *
# Your median function goes here (copy from denoise.py)
...
img = open(sys.argv)
img.show()
img = filter(img, median)	# denoise me please
img.show()
\end{pyverbatim}

\begin{callout}{\bctakecare}
Before finishing this task, be a thorough programmer and test your new scripts to see that they work:
\begin{alltt}
$ python blur2.py pcb.png
$ python denoise2.py guesswho.png
\end{alltt}
They {\em should} work, but unfortunately that is never good enough in the programming world.  Lot of little things can go wrong. {\em Certainty} is always better than {\em likelihood}.
\end{callout}

We will import file {\tt filter.py} into all of our future scripts. You have created your first useful library. {\bf Good job!} \scalebox{.55}{\bcsmbh}

\vspace{10mm}

\section{5. Highlighting image edges}

Now that we have some basic machinery in {\tt filter.py}, we can easily build new functionality. In this task, we want to highlight edges found within an image.  It is surprisingly easy to capture all of the important edges in an image, as shown in image (b) from \figref{jeepedges}. 

\begin{marginfigure}
\vspace{20mm}
\begin{center}
(a) \scalebox{.8}{\includegraphics{figures/jeep.png}}\\
(b) \scalebox{.8}{\includegraphics{figures/jeep-edges.png}}
\end{center}
\caption{Edges of an old photograph from World War II.  (a) original, (b) edges as computed by {\tt edges.py}.}
\label{jeepedges}
\end{marginfigure}

The mechanism we're going to use is derived from some serious calculus kung fu called the {\em Laplacian}, but which, in the end, reduces to 4 additions and a subtraction!  The intuition behind the Laplacian is that abrupt changes in brightness indicate edges, such as the transition from the darkness of a uniform to the brightness of a windshield edge.  As we did for blurring and denoising, we are going to slide a 3x3 region around the image to create new pixels at each {\tt x}, {\tt y}. That  means we can reuse our {\tt filter} function---we just need a {\tt laplace} function to pass to {\tt filter}.

To get started, here is the boilerplate code copied from {\tt denoise2.py} but with function name {\tt laplace} (the object of this task) passed as an argument to function {\tt filter}:

\begin{pyverbatim}
from filter import *
# define function laplace here
...
img = open(sys.argv)
img.show()
edges = filter(img, laplace)
edges.show()
\end{pyverbatim}

{\bf Create function} {\tt laplace} that takes region {\tt data} as an argument as usual. Have the function body  return the sum of the North, South, East, and West pixels minus 4 times the middle pixel from our usual region:

\begin{center}
\scalebox{.15}{\includegraphics{figures/3x3-region.png}}
\end{center}

\noindent That computation effectively compares the strength of the current pixel with those around it.

\begin{callout}{\bcinfo}
For those familiar with calculus, we are using the second partial derivative (i.e., acceleration) in x and y directions. The first derivative would detect edges even for gradual changes but the second derivative detects only really sharp changes. For a pixel fetching function $f$ operating on a 3x3 region around $(x,y)$, ``applying the {\em Laplacian}'' means computing a filtered image pixel at $x,y$ as:

{\footnotesize $f(x + 1,y) + f(x - 1,y) + f(x,y + 1) + f(x,y - 1) - 4f(x, y)$}

where $f(x,y)$ is equivalent to our {\tt pixels[x,y]}.
\end{callout}

For example, imagine a region centered over a vertical white line. The region might look like:

\begin{center}
\scalebox{.15}{\includegraphics{figures/vertical-line-region.png}}
\end{center}

\marginnote{Be aware of something that Pillow is doing for us automatically when we store values into an image with {\tt pixels[x,y] = v}.  {\bf If {\tt v} is out of range 0..255, Pillow clips {\tt v}}. So, for example, {\tt pixels[x,y] = -510} behaves like {\tt pixels[x,y] = 0} and {\tt pixels[x,y] = 510} behaves like {\tt pixels[x,y] = 255}. It doesn't affect edge detection or any of our other operations in future tasks but I wanted to point out that in a more advanced class we would {\bf scale} these pixel values instead of clipping them. Clipping has the effect of reducing contrast.
}

\noindent The {\tt laplace} function would return $255+255+0+0 - 4 \times 255 = -510$. 

Compare that to the opposite extreme where values are almost the same:

\begin{center}
\scalebox{.15}{\includegraphics{figures/flat-region.png}}
\end{center}

\noindent The {\tt laplace} function would return $18+19+15+21 - 4 \times 10 = 33$.

Once you have implemented your {\tt laplace} function, give it a try with some of the sample images you have such as the jeep or Obama:

\begin{lstlisting}[style=BashInputStyle]
$ python edges.py obama.png
\end{lstlisting}

It actually does a really good job capturing Obama's outline:\\
~\\

\begin{minipage}{\linewidth}
\makebox[\linewidth]{%
\scalebox{.2}{\includegraphics{figures/obama.png}} \scalebox{.20}{\includegraphics{figures/obama-edges}}
}
\end{minipage}

\section{6. Negative image edges}

\begin{marginfigure}
\vspace{45mm}
\begin{center}
(a) \scalebox{.8}{\includegraphics{figures/jeep.png}}\\
(b) \scalebox{.8}{\includegraphics{figures/jeep-negative-edges.png}}
\end{center}
\caption{Negative/inverted edges of an old photograph from World War II.  (a) original and (b) edges as computed by {\tt negative-edges.py}.}
\label{jeepedges}
\end{marginfigure}

Sometimes it's hard to see the edges in the white-on-black results from the previous task so, in this task, we're going to invert the edges image.  During lecture and in the images homework, you explored inverting an image. We need to apply that knowledge to invert the pixels computed by the {\em Laplacian}:

\begin{enumerate}
\item Copy {\tt edges.py} to new script {\tt negative-edges.py}.
\item Define a function called {\tt invert} that takes an argument, {\tt x}, and returns the inverted pixel value 255 - {\tt x}.
\item Instead of immediately calling {\tt show} on the image returned from the {\tt laplace} function, invert it by calling {\tt point} as described in the {\tt pil.txt} notes and passing it the name of the {\tt  invert} function.
\item Show the result returned from {\tt point}, which should be the inverted image.
\end{enumerate}

\noindent Give it a try with on the Obama image:

\begin{lstlisting}[style=BashInputStyle]
$ python negative-edges.py obama.png
\end{lstlisting}

\noindent Again, it does a really good job capturing Obama's outline:\\
~\\

\begin{minipage}{\linewidth}
\makebox[\linewidth]{%
\scalebox{.3}{\includegraphics{figures/obama.png}} \scalebox{.3}{\includegraphics{figures/obama-negative-edges}}
}
\end{minipage}

\newpage\section{7. Sharpening}

\begin{marginfigure}
\begin{center}
(a) \scalebox{.6}{\includegraphics{figures/bonkers-bw-zoom.png}}\\
(b) \scalebox{.6}{\includegraphics{figures/bonkers-sharp-zoom.png}}
\end{center}
\caption{Bonkers the cat portrait. (a) original and (b) sharpened as computed by {\tt sharpen.py}.}
\label{jeepedges}
\end{marginfigure}

Sharpening an image is a matter of highlighting the edges, which we know how to compute from the previous tasks. Script {\tt edges.py} computes just the edges so, to highlight the original image, we {\em subtract} that white-on-black edges image from the original.  You might imagine that {\em adding} the edges back in would be more appropriate and it sort of works, but the edges are slightly off. We get a better image by subtracting the high-valued light pixels because that darkens the edges in the original image, such as between the uniform and the windshield.\sidenote{Naturally, subtraction is just adding the negative and so we could add the image computed by {\tt negative-edges.py} instead of subtracting the image computed by {\tt edges.py}.} Let's start with the easy stuff:

\begin{enumerate}
\item Copy {\tt edges.py} to new script {\tt sharpen.py}.
\item Delete function {\tt invert} because we don't need it.
\item  Replace the line that calls {\tt point} with a call to a new function we'll create shortly called {\tt minus} that takes two image parameters, {\tt A} and {\tt B}. Pass in the original image and the image you get back from calling {\tt filter(img, laplace)}.
\end{enumerate}

That only leaves the task of {\bf creating function} {\tt minus} to subtract the pixels of one image from the pixels of another image like a 2-D matrix subtraction.  As we did before, we will return a modified version of a copy of an incoming image parameter. (In my solution, I arbitrarily chose to create and return a copy of {\tt A}.) Because you are getting really good at creating functions to manipulate images, the instructions for creating {\tt minus} in this  task are less specific than in previous tasks.  You need to fill in the body of this function:
 
\begin{pyverbatim}
# Return a new image whose pixels are A[x,y] - B[x,y]
def minus(A, B):
	...
\end{pyverbatim}

The mechanism is the same as before: iterating loop variables {\tt x} and {\tt y} across the entire image and processing the pixel at each location. The only difference between this function and {\tt filter} is that we want to operate on individual pixels not 3x3 regions.  In the inner loop, set {\tt pixels[x,y]} to the value of pixel {\tt A[x,y]} minus pixel {\tt B[x,y]}. Don't forget to return the image you filled in.

Here's how to run {\tt sharpen.py} on Bonkers the cat:

\begin{lstlisting}[style=BashInputStyle]
$ python sharpen.py bonkers-bw.png
\end{lstlisting}

\noindent \figref{bonkers3}, \figref{phobos3}, and \figref{jeep3} show some sample transformation sequences with original, {\em Laplacian}, and sharpened images.

\begin{minipage}{0.8 \linewidth}
\makebox[\linewidth]{%
\scalebox{.35}{\includegraphics{figures/bonkers-bw-zoom.png}} \scalebox{.35}{\includegraphics{figures/bonkers-edges-zoom.png}} \scalebox{.35}{\includegraphics{figures/bonkers-sharp-zoom.png}}
}
\captionof{figure}{Sharpening of a Bonkers the cat. Clockwise: (a) original, (b) edges as computed by {\tt edges.py}, (c) the sharpened image as computed by {\tt sharpen.py}.}
\label{bonkers3}
\end{minipage}

\begin{minipage}{0.8 \linewidth}
\makebox[\linewidth]{%
\scalebox{.45}{\includegraphics{figures/phobos1.png}}
\scalebox{.45}{\includegraphics{figures/phobos1-edges.png}}\\
\scalebox{.45}{\includegraphics{figures/phobos1-sharp.png}}
}
\captionof{figure}{Sharpening of Phobos asteroid from NASA. Clockwise: (a) original, (b) edges as computed by {\tt edges.py}, (c) the sharpened image as computed by {\tt sharpen.py}.}
\label{phobos3}
\end{minipage}

\begin{minipage}{0.8 \linewidth}
\makebox[\linewidth]{%
\scalebox{.45}{\includegraphics{figures/jeep.png}}
\scalebox{.45}{\includegraphics{figures/jeep-edges.png}}\\
\scalebox{.45}{\includegraphics{figures/jeep-sharp.png}}
}
\captionof{figure}{Sharpening of an old photograph from World War II. Clockwise: (a) original, (b) edges as computed by {\tt edges.py}, (c) the sharpened image as computed by {\tt sharpen.py}.}
\label{jeep3}
\end{minipage}


